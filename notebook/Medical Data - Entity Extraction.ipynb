{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<style>\n",
        "body {\n",
        "    font-family: 'Arial', sans-serif;  /* Change to your desired font */\n",
        "}\n",
        "</style>\n",
        "\n",
        "\n",
        "```\n",
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# Author: pcorreia@google.com\n",
        "```"
      ],
      "metadata": {
        "id": "hpyN8_QD5cIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entity Extraction with Gemini âœ¨\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "clc15c3rxBm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n"
      ],
      "metadata": {
        "id": "xmS3VhBW8ub4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Purpose of this notebook**\n",
        "\n",
        "The purpose of this notebook is to showcase how Gemini works with multi-modal inputs to generate insights and support customers that have either audio, image, or video assets. More info on Gemini's multi-modality [here](https://cloud.google.com/use-cases/multimodal-ai?hl=en).\n",
        "\n",
        "Specifically the scenario we are showcasing in this notebook is the creation of a pipeline that given a set of assets in a Google Cloud Storage bucket is able to create metadata that is accurate and informative about these assets.\n",
        "\n",
        "**Generic Prompts**\n",
        "\n",
        "The prompts are generic and have not been tailored to a specific content type. With further prompt engineering you'd expect to have more detailed metadata generate. For example: if most of your content is sports related, doing prompt that captures specific moments of that sport (red cards, penalties, etc) you'll have richer metadata.\n"
      ],
      "metadata": {
        "id": "JfWKCeBX57X_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before you start"
      ],
      "metadata": {
        "id": "uH327alV8xIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Requirements**\n",
        "\n",
        "Make sure you have the following resources in your GCP environment:\n",
        "\n",
        "\n",
        "*   Google cloud project with the APIs enabled;\n",
        "*   One Google cloud storage buckets that will store your reports\n",
        "*   Firestore enabled and with a collection created.\n",
        "*   And your report files place in the input bucket.\n",
        "\n",
        "Once you have this place, you'll be able to run the notebook.\n",
        "\n",
        "\n",
        "**Ingestion Pipeline**\n",
        "\n",
        "\n",
        "These are the relevant steps that the notebook will take you on:\n",
        "\n",
        "1.   Load The items from the input bucket;\n",
        "2.   Run the prompts for the metadata generation of your reports;\n"
      ],
      "metadata": {
        "id": "bWWYHey78lcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result**\n",
        "\n",
        "At the end of this pipeline you'll have all of the reports with the following json structure:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"Summary\": \"Summary of the content of the report, measurements and conclusions\",\n",
        "    \"PatientInfo\":{\n",
        "        \"Age\": \"e.g., 45\",\n",
        "        \"Sex\": \"e.g., Male/Female\",\n",
        "        \"RelevantMedicalHistory\": \"e.g., Hypertension, Diabetes\"\n",
        "    },\n",
        "    \"Reporter\":{\n",
        "        \"Name\": \"Name of the entity performing the test, e.g., 'Cardiovascular Imaging Center'\",\n",
        "        \"Address\": \"Full address of the entity, e.g., '123 Main Street, Anytown, CA 91234'\"\n",
        "    },\n",
        "    \"TestInfo\":{\n",
        "        \"Type\": \"Specify the type of the test or report, e.g., 'Echocardiogram'\",\n",
        "        \"Indications\": \"Provide the indications for the test/report'\",\n",
        "        \"ReportDate\": \"date when the report was created\"\n",
        "    },\n",
        "    \"Findings\":[\n",
        "        {\n",
        "            \"Heading\": \"Findings\",\n",
        "            \"Description\": \"Description of the finding'\"\n",
        "        },\n",
        "        {\n",
        "            \"Heading\": \"Findings\",\n",
        "            \"Description\": \"Description of the finding'\"\n",
        "        }\n",
        "    ],\n",
        "    \"Measurements\":[\n",
        "        {\n",
        "            \"Parameter\": \"Description of the parameter that is being measured\",\n",
        "            \"Value\": \"Value of the measurement\",\n",
        "            \"Unit\": \"unit of the measurement\"\n",
        "        },\n",
        "        {\n",
        "            \"Parameter\": \"Description of the parameter that is being measured\",\n",
        "            \"Value\": \"Value of the measurement\",\n",
        "            \"Unit\": \"unit of the measurement\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cpV4vSRootGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up ðŸ› "
      ],
      "metadata": {
        "id": "hMOTqxS6T9Yi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7Ln01eNJJmN"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade google-cloud-aiplatform google-cloud-speech firebase-admin tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qGmdWacJLnU"
      },
      "outputs": [],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ5O1-5gJP6O"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables"
      ],
      "metadata": {
        "id": "cJmhHE69UEJs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkC7zUXmJUN5"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"driven-crawler-436206\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "MODEL = \"gemini-1.5-flash-001\" # @param {type:\"string\"}\n",
        "INPUT_BUCKET=\"driven-crawler-436206-input\" # @param {type:\"string\"}\n",
        "#db collection for firestore\n",
        "DB_COLLECTION=\"default\"   # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n"
      ],
      "metadata": {
        "id": "Le6zvMW6Q4rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#common import\n",
        "import base64\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "import vertexai.preview.generative_models as generative_models\n",
        "from google.cloud import storage\n",
        "import re\n",
        "import json\n",
        "import tqdm\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "#storage\n",
        "import firebase_admin\n",
        "from firebase_admin import firestore\n",
        "\n",
        "#threading\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed"
      ],
      "metadata": {
        "id": "XIbKDszhQ6I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common Functions"
      ],
      "metadata": {
        "id": "wx9UzEKKUF0I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIBKRoL-Iby6"
      },
      "outputs": [],
      "source": [
        "def generate(prompt : list, model :str = MODEL) -> str:\n",
        "  vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "  model = GenerativeModel(\n",
        "    model,\n",
        "  )\n",
        "\n",
        "  generation_config = {\n",
        "      \"max_output_tokens\": 8192,\n",
        "      \"temperature\": 1,\n",
        "      \"top_p\": 0.95,\n",
        "  }\n",
        "\n",
        "  safety_settings = {\n",
        "      generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "      generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "      generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "      generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "  }\n",
        "\n",
        "  responses = model.generate_content(\n",
        "      prompt,\n",
        "      generation_config=generation_config,\n",
        "      safety_settings=safety_settings,\n",
        "      stream=False,\n",
        "  )\n",
        "  return responses.text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
        "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
        "    # The ID of your GCS bucket\n",
        "    # bucket_name = \"your-bucket-name\"\n",
        "\n",
        "    # The ID of your GCS object\n",
        "    # source_blob_name = \"storage-object-name\"\n",
        "\n",
        "    # The path to which the file should be downloaded\n",
        "    # destination_file_name = \"local/path/to/file\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "    # Construct a client side representation of a blob.\n",
        "    # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n",
        "    # any content from Google Cloud Storage. As we don't need additional data,\n",
        "    # using `Bucket.blob` is preferred here.\n",
        "    blob = bucket.blob(source_blob_name)\n",
        "    blob.download_to_filename(destination_file_name)\n",
        "\n",
        "    print(\n",
        "        \"Downloaded storage object {} from bucket {} to local file {}.\".format(\n",
        "            source_blob_name, bucket_name, destination_file_name\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "tz2EQESJZNwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_json_from_gcs(bucket_name, file_name):\n",
        "    \"\"\"Reads a JSON file from Google Cloud Storage into a Python dictionary.\n",
        "\n",
        "    Args:\n",
        "        bucket_name: The name of the GCS bucket.\n",
        "        file_name: The name of the JSON file within the bucket.\n",
        "\n",
        "    Returns:\n",
        "        A Python dictionary representing the JSON data, or None if an error occurred.\n",
        "    \"\"\"\n",
        "\n",
        "    # Remove 'gs://' prefix if present using replace()\n",
        "    bucket_name = bucket_name.replace(\"gs://\", \"\", 1)  # Replace only the first occurrence\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(file_name)\n",
        "\n",
        "    try:\n",
        "        contents = blob.download_as_string()\n",
        "        data = json.loads(contents)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading JSON from GCS: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "taf94cMWmuE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_bucket_files_pd(bucket_name):\n",
        "    \"\"\"\n",
        "    Lists files in a GCS bucket with properties (name, size, updated time).\n",
        "\n",
        "    Args:\n",
        "        bucket_name (str): Name of the GCS bucket.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing file properties.\n",
        "    \"\"\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs()\n",
        "\n",
        "    file_data = []\n",
        "    for blob in blobs:\n",
        "        file_data.append({\n",
        "            'file_name': blob.name,\n",
        "            'size': blob.size,\n",
        "              # Last updated timestamp\n",
        "            'type':blob.content_type,\n",
        "            'created': blob.time_created,\n",
        "            'updated': blob.updated,\n",
        "\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(file_data)\n",
        "    return df"
      ],
      "metadata": {
        "id": "mEKHf-tXk4d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_bucket_files(bucket_name):\n",
        "    \"\"\"\n",
        "    Lists files in a GCS bucket with properties (name, size, updated time).\n",
        "\n",
        "    Args:\n",
        "        bucket_name (str): Name of the GCS bucket.\n",
        "\n",
        "    Returns:\n",
        "        list: List of JSON objects containing file properties.\n",
        "    \"\"\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs()\n",
        "\n",
        "    file_data = []\n",
        "    for blob in blobs:\n",
        "        file_data.append({\n",
        "            'file_name': blob.name,\n",
        "            'size': blob.size,\n",
        "            'type': blob.content_type,\n",
        "            'created': blob.time_created,\n",
        "            'updated': blob.updated,\n",
        "        })\n",
        "\n",
        "    return file_data  # Return the list of JSON objects directly"
      ],
      "metadata": {
        "id": "zQJl4PbdL7P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metadata Generation ðŸ¤–\n",
        "\n"
      ],
      "metadata": {
        "id": "0O5qHzSiUI3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading assets\n",
        "\n",
        "Create a list of all the objects that are in the input bucket."
      ],
      "metadata": {
        "id": "TeosX91JUV5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = list_bucket_files(INPUT_BUCKET)\n",
        "file_list"
      ],
      "metadata": {
        "id": "XlCI_k8-k9tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Medical Reports âš•\n",
        "\n"
      ],
      "metadata": {
        "id": "yoOXJbIfFShD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_metadata(prompt : list, model :str = MODEL) -> str:\n",
        "  vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "  model = GenerativeModel(\n",
        "    model,\n",
        "  )\n",
        "\n",
        "  generation_config = {\n",
        "      \"max_output_tokens\": 8192,\n",
        "      \"temperature\": 1,\n",
        "      \"top_p\": 0.95,\n",
        "  }\n",
        "\n",
        "  safety_settings = {\n",
        "      generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "      generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "      generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "      generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "  }\n",
        "\n",
        "  responses = model.generate_content(\n",
        "      prompt,\n",
        "      generation_config=generation_config,\n",
        "      safety_settings=safety_settings,\n",
        "      stream=False,\n",
        "  )\n",
        "\n",
        "  return responses.text\n",
        "\n"
      ],
      "metadata": {
        "id": "JFevVJTjaTPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a image metadata\n",
        "def generate_metadata_report(blob_uri: str, mime_type: str, model:str) -> str:\n",
        "  report_asset = Part.from_uri(\n",
        "      mime_type=mime_type,\n",
        "      uri=blob_uri)\n",
        "\n",
        "  prompt = \"\"\"Extract the following information from the provided echocardiogram report and structure it in a JSON object according to the format below. If a piece of information is not available in the report, leave the corresponding field blank or use \\'N/A\\'. Ensure all values are extracted accurately and include appropriate units where applicable.\n",
        "JSON format:\n",
        "```\n",
        "{\n",
        "    \"Summary\": \"Summary of the content of the report, measurements and conclusions\",\n",
        "    \"PatientInfo\":{\n",
        "        \"Age\": \"e.g., 45\",\n",
        "        \"Sex\": \"e.g., Male/Female\",\n",
        "        \"RelevantMedicalHistory\": \"e.g., Hypertension, Diabetes\"\n",
        "    },\n",
        "    \"Reporter\":{\n",
        "        \"Name\": \"Name of the entity performing the test, e.g., 'Cardiovascular Imaging Center'\",\n",
        "        \"Address\": \"Full address of the entity, e.g., '123 Main Street, Anytown, CA 91234'\"\n",
        "    },\n",
        "    \"TestInfo\":{\n",
        "        \"Type\": \"Specify the type of the test or report, e.g., 'Echocardiogram'\",\n",
        "        \"Indications\": \"Provide the indications for the test/report'\",\n",
        "        \"ReportDate\": \"date when the report was created\"\n",
        "    },\n",
        "    \"Findings\":[\n",
        "        {\n",
        "            \"Heading\": \"Findings\",\n",
        "            \"Description\": \"Description of the finding'\"\n",
        "        },\n",
        "        {\n",
        "            \"Heading\": \"Findings\",\n",
        "            \"Description\": \"Description of the finding'\"\n",
        "        }\n",
        "    ],\n",
        "    \"Measurements\":[\n",
        "        {\n",
        "            \"Parameter\": \"Description of the parameter that is being measured\",\n",
        "            \"Value\": \"Value of the measurement\",\n",
        "            \"Unit\": \"unit of the measurement\"\n",
        "        },\n",
        "        {\n",
        "            \"Parameter\": \"Description of the parameter that is being measured\",\n",
        "            \"Value\": \"Value of the measurement\",\n",
        "            \"Unit\": \"unit of the measurement\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "```\"\"\"\n",
        "\n",
        "  result_text = generate_metadata(prompt=[report_asset, prompt], model = model )\n",
        "\n",
        "\n",
        "  return result_text"
      ],
      "metadata": {
        "id": "n-Y4bg5FZZYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_report(report : json):\n",
        "  \"\"\"Processes a single row from the image list.\"\"\"\n",
        "\n",
        "  blob_uri = f\"gs://{INPUT_BUCKET}/{report['file_name']}\"\n",
        "  try:\n",
        "    result = generate_metadata_report(blob_uri, report['type'], MODEL)\n",
        "    # print(f\"Processing {image['file_name']} > {result}\")\n",
        "\n",
        "    response_text = re.sub(r\"json|```\", \"\", result)\n",
        "    report['metadata'] = json.loads(response_text)\n",
        "    return result\n",
        "  except Exception as e:\n",
        "      print(f\"Error processing {report['file_name']} {e}\")\n",
        "\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    # Submit tasks to the executor\n",
        "    futures = [executor.submit(process_report, report) for report in file_list]\n",
        "\n",
        "    # You can remove the tqdm loop if you don't need progress updates\n",
        "    for _ in tqdm.tqdm(as_completed(futures), total=len(futures)):\n",
        "        pass  # No need to process individual results here\n",
        "\n",
        "print('Report Metadata Generated')\n"
      ],
      "metadata": {
        "id": "eyBUUKbpaDgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the item name from the file name\n",
        "for report in file_list:\n",
        "  report['name'] = report['file_name'].split('.')[0]\n"
      ],
      "metadata": {
        "id": "Ps41qSzmbre0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storing Metadata ðŸ’¾"
      ],
      "metadata": {
        "id": "iOW2QOpEpRR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# starting the firebase db\n",
        "# Initialize Firebase Admin SDK\n",
        "firebase_admin.initialize_app()\n"
      ],
      "metadata": {
        "id": "DaTDafZRiwnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a reference to the Firestore database\n",
        "db = firestore.client()"
      ],
      "metadata": {
        "id": "kt4YJMCNuydy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for report in tqdm.tqdm(file_list, desc=\"Storing report metada\"):\n",
        "  doc_ref = db.collection(DB_COLLECTION).document(report['name'])\n",
        "  doc_ref.set(report)"
      ],
      "metadata": {
        "id": "7BXgnwoBcS-9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Medical Data - Entity Extraction.ipynb",
      "collapsed_sections": [
        "xmS3VhBW8ub4",
        "cJmhHE69UEJs",
        "Le6zvMW6Q4rf",
        "wx9UzEKKUF0I",
        "TeosX91JUV5u",
        "yoOXJbIfFShD",
        "iOW2QOpEpRR7"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}